{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42 # is the answer\n",
        "NON_ALPHA = re.compile(\"[^A-Za-z_0-9]\")\n",
        "RNG = np.random.RandomState(SEED)\n",
        "MAX_HASH = np.uint64((1 << 32) - 1)\n",
        "MERSENNE_PRIME = np.uint64((1 << 61) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4294967295"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# max uint32 value\n",
        "MAX_HASH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4294967296"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "2**32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Compute the total number of documents from all the datasets\n",
        "\n",
        "import json \n",
        "with open('groups.json') as fd:\n",
        "    config = json.load(fd)\n",
        "dataset_list = config['group_1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/admin/home-mistobaan/pilev2-venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "loading datasets:   0%|          | 0/11 [00:00<?, ?it/s]/admin/home-mistobaan/pilev2-venv/lib/python3.8/site-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
            "  warnings.warn(\n",
            "loading datasets: 100%|██████████| 11/11 [01:07<00:00,  6.13s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import datasets\n",
        "import os\n",
        "dataset_description_collection = {}\n",
        "\n",
        "basedir =  '/fsx/shared/pilev2_local_deduped'\n",
        "total = 0\n",
        "for dataset_name in tqdm(dataset_list, desc=\"loading datasets\"):\n",
        "    dataset_path = os.path.join(basedir, dataset_name)\n",
        "    ds = datasets.load_from_disk(dataset_path, fs=None, keep_in_memory=None)\n",
        "    dataset_description_collection[dataset_name] = ds\n",
        "    total += len(ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37203245"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1384081438530025"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total **2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets.config.IN_MEMORY_MAX_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Break down the Embed func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Tuple, Any, Dict, Iterable\n",
        "\n",
        "from itertools import tee\n",
        "\n",
        "\n",
        "def ngrams(sequence: List[str], n: int) -> Iterable:\n",
        "    \"\"\"\n",
        "    Directly taken from nltk package to avoid dependency.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sequence : list\n",
        "        The sequence of items to be n-grammed.\n",
        "    n : int\n",
        "        The order of the n-grams to be extracted.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Iterable\n",
        "        The n-grams generated from the sequence.\n",
        "    \"\"\"\n",
        "    iterables = tee(sequence, n)\n",
        "    for i, sub_iterable in enumerate(iterables):\n",
        "        for _ in range(i):\n",
        "            next(sub_iterable, None)\n",
        "    return zip(*iterables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install nltk\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# An n-gram is a contiguous sequence of n items\n",
        "# An n-gram of size 1 is referred to as a unigram\n",
        "list(nltk.ngrams('1234', 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('1', '2', '3', '4', '5'), ('2', '3', '4', '5', '6')]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(nltk.ngrams('123456', 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ngrams(text, n):\n",
        "    n-=1\n",
        "    return [text[i-n:i+1] for i,char in enumerate(text)][n:] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "keys = list(dataset_description_collection.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'arXiv_ver2'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keys[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# WARNING THIS LOADS 130GB IN MEMORY\n",
        "# content = dataset_description_collection[keys[0]]['text'][0]\n",
        "ngram_size = 5\n",
        "import hashlib\n",
        "import struct\n",
        "\n",
        "def sha1_hash32(data: bytes) -> int:\n",
        "    \"\"\"\n",
        "    Compute hash32 (int) value of a sequence of bytes\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : bytes\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "    \"\"\"\n",
        "    # In cryptography, SHA-1 (Secure Hash Algorithm 1) is a cryptographically broken \n",
        "    # but still widely used hash function which takes an input and \n",
        "    # produces a 160-bit (20-byte) hash value known as a message digest \n",
        "    # typically rendered as a hexadecimal number, 40 digits long. \n",
        "    digest = hashlib.sha1(data).digest()\n",
        "    top4bytes = digest[:4]\n",
        "    # given 4 bytes pack it to a single uint32\n",
        "    hash32bit , *_ = struct.unpack(\"<I\", top4bytes)\n",
        "    return hash32bit\n",
        "\n",
        "\n",
        "def convert_chunks_to_hash_list(chunks):\n",
        "   return [sha1_hash32(chunk) for chunk in chunks]\n",
        "\n",
        "\n",
        "for ix, row in enumerate(dataset_description_collection['arXiv_ver2']):\n",
        "    if ix == 3:\n",
        "        break\n",
        "    # don't use empty/only whitespace documents \n",
        "    document = row['text'].strip()\n",
        "    # TODO: apply utf8 cleanup step before\n",
        "    if not document:\n",
        "        continue\n",
        "    chunks = NON_ALPHA.split(document)\n",
        "    content_as_ngram = set(\" \".join(ngram).encode(\"utf-8\") # TODO: NORMALIZE UTF8 \n",
        "                                    for ngram in ngrams(chunks, ngram_size))\n",
        "    # for each document we have a bunch of chunks. each chunk is UNIQUE within the chunk_set\n",
        "    hash_values = np.array(convert_chunks_to_hash_list(content_as_ngram), dtype=np.uint64)  # noqa: E501\n",
        "    # vector of hash32 values of the chunked document\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_perm = 256\n",
        "SEED = 42\n",
        "NON_ALPHA = re.compile(\"[^A-Za-z_0-9]\")\n",
        "MERSENNE_TWISTER_RNG = np.random.RandomState(SEED)\n",
        "# Container for the slow Mersenne Twister pseudo-random number generator. \n",
        "# Consider using a different BitGenerator with the Generator container instead.\n",
        "# TODO: USE NEW RANDOM GENERATION CODE FOR *SPEED*\n",
        "\n",
        "MAX_HASH = np.uint64((1 << 32) - 1)\n",
        "MERSENNE_PRIME = np.uint64((1 << 61) - 1)\n",
        "DATA_SIZE = len(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def np64array(int_array):\n",
        "    return np.array(int_array, dtype=np.uint64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2305843009213693951"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MERSENNE_PRIME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Return random integers from low (inclusive) to high (exclusive).\n",
        "# Return random integers from the “discrete uniform” distribution of the specified dtype in the “half-open” interval [low, high). If high is None (the default), then results are from [0, low)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "partitions = [\n",
        "    (\n",
        "        MERSENNE_TWISTER_RNG.randint(1, MERSENNE_PRIME, dtype=np.uint64),\n",
        "        MERSENNE_TWISTER_RNG.randint(0, MERSENNE_PRIME, dtype=np.uint64),\n",
        "    )\n",
        "    for _ in range(num_perm)\n",
        "]\n",
        "\n",
        "PERMUTATIONS = np64array(partitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(256, 2)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PERMUTATIONS.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "permutations = PERMUTATIONS.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "a, b = permutations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(63260, 19132, 256, 10186)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(document), len(NON_ALPHA.split(document)), *a.shape, hash_values.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_hash = np.tile(a, (len(hash_values), 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10186, 256)"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "table_hash.shape\n",
        "# for each hash we have a random number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(256,)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = (hash_values * table_hash.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "phv = np.bitwise_and( X % MERSENNE_PRIME, MAX_HASH) \n",
        "# np.bitwise_and: Compute the bit-wise AND of two arrays element-wise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(256, 10186)"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phv.shape\n",
        "# Number of partitions X number of unique chunks (as hash32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "hashvalues = np.ones(num_perm, dtype=np.uint64) * MAX_HASH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((256,), (256, 10186))"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hashvalues.shape, phv.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 0.7\n",
        "num_perm = 256\n",
        "B, R = optimal_param(threshold, num_perm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HASH_RANGES = [(i * R, (i + 1) * R) for i in range(B)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "hash_value_for_each_partition = np.vstack([phv.T, hashvalues]).min(axis=0)\n",
        "\n",
        "# Hs = [bytes(hashvalues[start:end].byteswap().data) for start, end in hashranges]\n",
        "# return {\"__signatures__\": Hs, \"__id__\": idx}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 33.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /admin/home-mistobaan/pilev2-venv/lib/python3.8/site-packages (from scipy) (1.24.1)\n",
            "Installing collected packages: scipy\n",
            "Successfully installed scipy-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy\n",
        "integrate = scipy.integrate.quad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mSignature:\u001b[0m\n",
            "\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mepsabs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.49e-08\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mepsrel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.49e-08\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mwvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mwopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mmaxp1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mlimlst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mcomplex_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDocstring:\u001b[0m\n",
            "Compute a definite integral.\n",
            "\n",
            "Integrate func from `a` to `b` (possibly infinite interval) using a\n",
            "technique from the Fortran library QUADPACK.\n",
            "\n",
            "Parameters\n",
            "----------\n",
            "func : {function, scipy.LowLevelCallable}\n",
            "    A Python function or method to integrate. If `func` takes many\n",
            "    arguments, it is integrated along the axis corresponding to the\n",
            "    first argument.\n",
            "\n",
            "    If the user desires improved integration performance, then `f` may\n",
            "    be a `scipy.LowLevelCallable` with one of the signatures::\n",
            "\n",
            "        double func(double x)\n",
            "        double func(double x, void *user_data)\n",
            "        double func(int n, double *xx)\n",
            "        double func(int n, double *xx, void *user_data)\n",
            "\n",
            "    The ``user_data`` is the data contained in the `scipy.LowLevelCallable`.\n",
            "    In the call forms with ``xx``,  ``n`` is the length of the ``xx``\n",
            "    array which contains ``xx[0] == x`` and the rest of the items are\n",
            "    numbers contained in the ``args`` argument of quad.\n",
            "\n",
            "    In addition, certain ctypes call signatures are supported for\n",
            "    backward compatibility, but those should not be used in new code.\n",
            "a : float\n",
            "    Lower limit of integration (use -numpy.inf for -infinity).\n",
            "b : float\n",
            "    Upper limit of integration (use numpy.inf for +infinity).\n",
            "args : tuple, optional\n",
            "    Extra arguments to pass to `func`.\n",
            "full_output : int, optional\n",
            "    Non-zero to return a dictionary of integration information.\n",
            "    If non-zero, warning messages are also suppressed and the\n",
            "    message is appended to the output tuple.\n",
            "complex_func : bool, optional\n",
            "    Indicate if the function's (`func`) return type is real\n",
            "    (``complex_func=False``: default) or complex (``complex_func=True``).\n",
            "    In both cases, the function's argument is real.\n",
            "    If full_output is also non-zero, the `infodict`, `message`, and\n",
            "    `explain` for the real and complex components are returned in\n",
            "    a dictionary with keys \"real output\" and \"imag output\".\n",
            "\n",
            "Returns\n",
            "-------\n",
            "y : float\n",
            "    The integral of func from `a` to `b`.\n",
            "abserr : float\n",
            "    An estimate of the absolute error in the result.\n",
            "infodict : dict\n",
            "    A dictionary containing additional information.\n",
            "message\n",
            "    A convergence message.\n",
            "explain\n",
            "    Appended only with 'cos' or 'sin' weighting and infinite\n",
            "    integration limits, it contains an explanation of the codes in\n",
            "    infodict['ierlst']\n",
            "\n",
            "Other Parameters\n",
            "----------------\n",
            "epsabs : float or int, optional\n",
            "    Absolute error tolerance. Default is 1.49e-8. `quad` tries to obtain\n",
            "    an accuracy of ``abs(i-result) <= max(epsabs, epsrel*abs(i))``\n",
            "    where ``i`` = integral of `func` from `a` to `b`, and ``result`` is the\n",
            "    numerical approximation. See `epsrel` below.\n",
            "epsrel : float or int, optional\n",
            "    Relative error tolerance. Default is 1.49e-8.\n",
            "    If ``epsabs <= 0``, `epsrel` must be greater than both 5e-29\n",
            "    and ``50 * (machine epsilon)``. See `epsabs` above.\n",
            "limit : float or int, optional\n",
            "    An upper bound on the number of subintervals used in the adaptive\n",
            "    algorithm.\n",
            "points : (sequence of floats,ints), optional\n",
            "    A sequence of break points in the bounded integration interval\n",
            "    where local difficulties of the integrand may occur (e.g.,\n",
            "    singularities, discontinuities). The sequence does not have\n",
            "    to be sorted. Note that this option cannot be used in conjunction\n",
            "    with ``weight``.\n",
            "weight : float or int, optional\n",
            "    String indicating weighting function. Full explanation for this\n",
            "    and the remaining arguments can be found below.\n",
            "wvar : optional\n",
            "    Variables for use with weighting functions.\n",
            "wopts : optional\n",
            "    Optional input for reusing Chebyshev moments.\n",
            "maxp1 : float or int, optional\n",
            "    An upper bound on the number of Chebyshev moments.\n",
            "limlst : int, optional\n",
            "    Upper bound on the number of cycles (>=3) for use with a sinusoidal\n",
            "    weighting and an infinite end-point.\n",
            "\n",
            "See Also\n",
            "--------\n",
            "dblquad : double integral\n",
            "tplquad : triple integral\n",
            "nquad : n-dimensional integrals (uses `quad` recursively)\n",
            "fixed_quad : fixed-order Gaussian quadrature\n",
            "quadrature : adaptive Gaussian quadrature\n",
            "odeint : ODE integrator\n",
            "ode : ODE integrator\n",
            "simpson : integrator for sampled data\n",
            "romb : integrator for sampled data\n",
            "scipy.special : for coefficients and roots of orthogonal polynomials\n",
            "\n",
            "Notes\n",
            "-----\n",
            "\n",
            "**Extra information for quad() inputs and outputs**\n",
            "\n",
            "If full_output is non-zero, then the third output argument\n",
            "(infodict) is a dictionary with entries as tabulated below. For\n",
            "infinite limits, the range is transformed to (0,1) and the\n",
            "optional outputs are given with respect to this transformed range.\n",
            "Let M be the input argument limit and let K be infodict['last'].\n",
            "The entries are:\n",
            "\n",
            "'neval'\n",
            "    The number of function evaluations.\n",
            "'last'\n",
            "    The number, K, of subintervals produced in the subdivision process.\n",
            "'alist'\n",
            "    A rank-1 array of length M, the first K elements of which are the\n",
            "    left end points of the subintervals in the partition of the\n",
            "    integration range.\n",
            "'blist'\n",
            "    A rank-1 array of length M, the first K elements of which are the\n",
            "    right end points of the subintervals.\n",
            "'rlist'\n",
            "    A rank-1 array of length M, the first K elements of which are the\n",
            "    integral approximations on the subintervals.\n",
            "'elist'\n",
            "    A rank-1 array of length M, the first K elements of which are the\n",
            "    moduli of the absolute error estimates on the subintervals.\n",
            "'iord'\n",
            "    A rank-1 integer array of length M, the first L elements of\n",
            "    which are pointers to the error estimates over the subintervals\n",
            "    with ``L=K`` if ``K<=M/2+2`` or ``L=M+1-K`` otherwise. Let I be the\n",
            "    sequence ``infodict['iord']`` and let E be the sequence\n",
            "    ``infodict['elist']``.  Then ``E[I[1]], ..., E[I[L]]`` forms a\n",
            "    decreasing sequence.\n",
            "\n",
            "If the input argument points is provided (i.e., it is not None),\n",
            "the following additional outputs are placed in the output\n",
            "dictionary. Assume the points sequence is of length P.\n",
            "\n",
            "'pts'\n",
            "    A rank-1 array of length P+2 containing the integration limits\n",
            "    and the break points of the intervals in ascending order.\n",
            "    This is an array giving the subintervals over which integration\n",
            "    will occur.\n",
            "'level'\n",
            "    A rank-1 integer array of length M (=limit), containing the\n",
            "    subdivision levels of the subintervals, i.e., if (aa,bb) is a\n",
            "    subinterval of ``(pts[1], pts[2])`` where ``pts[0]`` and ``pts[2]``\n",
            "    are adjacent elements of ``infodict['pts']``, then (aa,bb) has level l\n",
            "    if ``|bb-aa| = |pts[2]-pts[1]| * 2**(-l)``.\n",
            "'ndin'\n",
            "    A rank-1 integer array of length P+2. After the first integration\n",
            "    over the intervals (pts[1], pts[2]), the error estimates over some\n",
            "    of the intervals may have been increased artificially in order to\n",
            "    put their subdivision forward. This array has ones in slots\n",
            "    corresponding to the subintervals for which this happens.\n",
            "\n",
            "**Weighting the integrand**\n",
            "\n",
            "The input variables, *weight* and *wvar*, are used to weight the\n",
            "integrand by a select list of functions. Different integration\n",
            "methods are used to compute the integral with these weighting\n",
            "functions, and these do not support specifying break points. The\n",
            "possible values of weight and the corresponding weighting functions are.\n",
            "\n",
            "==========  ===================================   =====================\n",
            "``weight``  Weight function used                  ``wvar``\n",
            "==========  ===================================   =====================\n",
            "'cos'       cos(w*x)                              wvar = w\n",
            "'sin'       sin(w*x)                              wvar = w\n",
            "'alg'       g(x) = ((x-a)**alpha)*((b-x)**beta)   wvar = (alpha, beta)\n",
            "'alg-loga'  g(x)*log(x-a)                         wvar = (alpha, beta)\n",
            "'alg-logb'  g(x)*log(b-x)                         wvar = (alpha, beta)\n",
            "'alg-log'   g(x)*log(x-a)*log(b-x)                wvar = (alpha, beta)\n",
            "'cauchy'    1/(x-c)                               wvar = c\n",
            "==========  ===================================   =====================\n",
            "\n",
            "wvar holds the parameter w, (alpha, beta), or c depending on the weight\n",
            "selected. In these expressions, a and b are the integration limits.\n",
            "\n",
            "For the 'cos' and 'sin' weighting, additional inputs and outputs are\n",
            "available.\n",
            "\n",
            "For finite integration limits, the integration is performed using a\n",
            "Clenshaw-Curtis method which uses Chebyshev moments. For repeated\n",
            "calculations, these moments are saved in the output dictionary:\n",
            "\n",
            "'momcom'\n",
            "    The maximum level of Chebyshev moments that have been computed,\n",
            "    i.e., if ``M_c`` is ``infodict['momcom']`` then the moments have been\n",
            "    computed for intervals of length ``|b-a| * 2**(-l)``,\n",
            "    ``l=0,1,...,M_c``.\n",
            "'nnlog'\n",
            "    A rank-1 integer array of length M(=limit), containing the\n",
            "    subdivision levels of the subintervals, i.e., an element of this\n",
            "    array is equal to l if the corresponding subinterval is\n",
            "    ``|b-a|* 2**(-l)``.\n",
            "'chebmo'\n",
            "    A rank-2 array of shape (25, maxp1) containing the computed\n",
            "    Chebyshev moments. These can be passed on to an integration\n",
            "    over the same interval by passing this array as the second\n",
            "    element of the sequence wopts and passing infodict['momcom'] as\n",
            "    the first element.\n",
            "\n",
            "If one of the integration limits is infinite, then a Fourier integral is\n",
            "computed (assuming w neq 0). If full_output is 1 and a numerical error\n",
            "is encountered, besides the error message attached to the output tuple,\n",
            "a dictionary is also appended to the output tuple which translates the\n",
            "error codes in the array ``info['ierlst']`` to English messages. The\n",
            "output information dictionary contains the following entries instead of\n",
            "'last', 'alist', 'blist', 'rlist', and 'elist':\n",
            "\n",
            "'lst'\n",
            "    The number of subintervals needed for the integration (call it ``K_f``).\n",
            "'rslst'\n",
            "    A rank-1 array of length M_f=limlst, whose first ``K_f`` elements\n",
            "    contain the integral contribution over the interval\n",
            "    ``(a+(k-1)c, a+kc)`` where ``c = (2*floor(|w|) + 1) * pi / |w|``\n",
            "    and ``k=1,2,...,K_f``.\n",
            "'erlst'\n",
            "    A rank-1 array of length ``M_f`` containing the error estimate\n",
            "    corresponding to the interval in the same position in\n",
            "    ``infodict['rslist']``.\n",
            "'ierlst'\n",
            "    A rank-1 integer array of length ``M_f`` containing an error flag\n",
            "    corresponding to the interval in the same position in\n",
            "    ``infodict['rslist']``.  See the explanation dictionary (last entry\n",
            "    in the output tuple) for the meaning of the codes.\n",
            "\n",
            "\n",
            "**Details of QUADPACK level routines**\n",
            "\n",
            "`quad` calls routines from the FORTRAN library QUADPACK. This section\n",
            "provides details on the conditions for each routine to be called and a\n",
            "short description of each routine. The routine called depends on\n",
            "`weight`, `points` and the integration limits `a` and `b`.\n",
            "\n",
            "================  ==============  ==========  =====================\n",
            "QUADPACK routine  `weight`        `points`    infinite bounds\n",
            "================  ==============  ==========  =====================\n",
            "qagse             None            No          No\n",
            "qagie             None            No          Yes\n",
            "qagpe             None            Yes         No\n",
            "qawoe             'sin', 'cos'    No          No\n",
            "qawfe             'sin', 'cos'    No          either `a` or `b`\n",
            "qawse             'alg*'          No          No\n",
            "qawce             'cauchy'        No          No\n",
            "================  ==============  ==========  =====================\n",
            "\n",
            "The following provides a short description from [1]_ for each\n",
            "routine.\n",
            "\n",
            "qagse\n",
            "    is an integrator based on globally adaptive interval\n",
            "    subdivision in connection with extrapolation, which will\n",
            "    eliminate the effects of integrand singularities of\n",
            "    several types.\n",
            "qagie\n",
            "    handles integration over infinite intervals. The infinite range is\n",
            "    mapped onto a finite interval and subsequently the same strategy as\n",
            "    in ``QAGS`` is applied.\n",
            "qagpe\n",
            "    serves the same purposes as QAGS, but also allows the\n",
            "    user to provide explicit information about the location\n",
            "    and type of trouble-spots i.e. the abscissae of internal\n",
            "    singularities, discontinuities and other difficulties of\n",
            "    the integrand function.\n",
            "qawoe\n",
            "    is an integrator for the evaluation of\n",
            "    :math:`\\int^b_a \\cos(\\omega x)f(x)dx` or\n",
            "    :math:`\\int^b_a \\sin(\\omega x)f(x)dx`\n",
            "    over a finite interval [a,b], where :math:`\\omega` and :math:`f`\n",
            "    are specified by the user. The rule evaluation component is based\n",
            "    on the modified Clenshaw-Curtis technique\n",
            "\n",
            "    An adaptive subdivision scheme is used in connection\n",
            "    with an extrapolation procedure, which is a modification\n",
            "    of that in ``QAGS`` and allows the algorithm to deal with\n",
            "    singularities in :math:`f(x)`.\n",
            "qawfe\n",
            "    calculates the Fourier transform\n",
            "    :math:`\\int^\\infty_a \\cos(\\omega x)f(x)dx` or\n",
            "    :math:`\\int^\\infty_a \\sin(\\omega x)f(x)dx`\n",
            "    for user-provided :math:`\\omega` and :math:`f`. The procedure of\n",
            "    ``QAWO`` is applied on successive finite intervals, and convergence\n",
            "    acceleration by means of the :math:`\\varepsilon`-algorithm is applied\n",
            "    to the series of integral approximations.\n",
            "qawse\n",
            "    approximate :math:`\\int^b_a w(x)f(x)dx`, with :math:`a < b` where\n",
            "    :math:`w(x) = (x-a)^{\\alpha}(b-x)^{\\beta}v(x)` with\n",
            "    :math:`\\alpha,\\beta > -1`, where :math:`v(x)` may be one of the\n",
            "    following functions: :math:`1`, :math:`\\log(x-a)`, :math:`\\log(b-x)`,\n",
            "    :math:`\\log(x-a)\\log(b-x)`.\n",
            "\n",
            "    The user specifies :math:`\\alpha`, :math:`\\beta` and the type of the\n",
            "    function :math:`v`. A globally adaptive subdivision strategy is\n",
            "    applied, with modified Clenshaw-Curtis integration on those\n",
            "    subintervals which contain `a` or `b`.\n",
            "qawce\n",
            "    compute :math:`\\int^b_a f(x) / (x-c)dx` where the integral must be\n",
            "    interpreted as a Cauchy principal value integral, for user specified\n",
            "    :math:`c` and :math:`f`. The strategy is globally adaptive. Modified\n",
            "    Clenshaw-Curtis integration is used on those intervals containing the\n",
            "    point :math:`x = c`.\n",
            "\n",
            "**Integration of Complex Function of a Real Variable**\n",
            "\n",
            "A complex valued function, :math:`f`, of a real variable can be written as\n",
            ":math:`f = g + ih`.  Similarly, the integral of :math:`f` can be\n",
            "written as\n",
            "\n",
            ".. math::\n",
            "    \\int_a^b f(x) dx = \\int_a^b g(x) dx + i\\int_a^b h(x) dx\n",
            "\n",
            "assuming that the integrals of :math:`g` and :math:`h` exist\n",
            "over the interval :math:`[a,b]` [2]_. Therefore, ``quad`` integrates\n",
            "complex-valued functions by integrating the real and imaginary components\n",
            "separately.\n",
            "\n",
            "\n",
            "References\n",
            "----------\n",
            "\n",
            ".. [1] Piessens, Robert; de Doncker-Kapenga, Elise;\n",
            "       Überhuber, Christoph W.; Kahaner, David (1983).\n",
            "       QUADPACK: A subroutine package for automatic integration.\n",
            "       Springer-Verlag.\n",
            "       ISBN 978-3-540-12553-2.\n",
            "\n",
            ".. [2] McCullough, Thomas; Phillips, Keith (1973).\n",
            "       Foundations of Analysis in the Complex Plane.\n",
            "       Holt Rinehart Winston.\n",
            "       ISBN 0-03-086370-8\n",
            "\n",
            "Examples\n",
            "--------\n",
            "Calculate :math:`\\int^4_0 x^2 dx` and compare with an analytic result\n",
            "\n",
            ">>> from scipy import integrate\n",
            ">>> import numpy as np\n",
            ">>> x2 = lambda x: x**2\n",
            ">>> integrate.quad(x2, 0, 4)\n",
            "(21.333333333333332, 2.3684757858670003e-13)\n",
            ">>> print(4**3 / 3.)  # analytical result\n",
            "21.3333333333\n",
            "\n",
            "Calculate :math:`\\int^\\infty_0 e^{-x} dx`\n",
            "\n",
            ">>> invexp = lambda x: np.exp(-x)\n",
            ">>> integrate.quad(invexp, 0, np.inf)\n",
            "(1.0, 5.842605999138044e-11)\n",
            "\n",
            "Calculate :math:`\\int^1_0 a x \\,dx` for :math:`a = 1, 3`\n",
            "\n",
            ">>> f = lambda x, a: a*x\n",
            ">>> y, err = integrate.quad(f, 0, 1, args=(1,))\n",
            ">>> y\n",
            "0.5\n",
            ">>> y, err = integrate.quad(f, 0, 1, args=(3,))\n",
            ">>> y\n",
            "1.5\n",
            "\n",
            "Calculate :math:`\\int^1_0 x^2 + y^2 dx` with ctypes, holding\n",
            "y parameter as 1::\n",
            "\n",
            "    testlib.c =>\n",
            "        double func(int n, double args[n]){\n",
            "            return args[0]*args[0] + args[1]*args[1];}\n",
            "    compile to library testlib.*\n",
            "\n",
            "::\n",
            "\n",
            "   from scipy import integrate\n",
            "   import ctypes\n",
            "   lib = ctypes.CDLL('/home/.../testlib.*') #use absolute path\n",
            "   lib.func.restype = ctypes.c_double\n",
            "   lib.func.argtypes = (ctypes.c_int,ctypes.c_double)\n",
            "   integrate.quad(lib.func,0,1,(1))\n",
            "   #(1.3333333333333333, 1.4802973661668752e-14)\n",
            "   print((1.0**3/3.0 + 1.0) - (0.0**3/3.0 + 0.0)) #Analytic result\n",
            "   # 1.3333333333333333\n",
            "\n",
            "Be aware that pulse shapes and other sharp features as compared to the\n",
            "size of the integration interval may not be integrated correctly using\n",
            "this method. A simplified example of this limitation is integrating a\n",
            "y-axis reflected step function with many zero values within the integrals\n",
            "bounds.\n",
            "\n",
            ">>> y = lambda x: 1 if x<=0 else 0\n",
            ">>> integrate.quad(y, -1, 1)\n",
            "(1.0, 1.1102230246251565e-14)\n",
            ">>> integrate.quad(y, -1, 100)\n",
            "(1.0000000002199108, 1.0189464580163188e-08)\n",
            ">>> integrate.quad(y, -1, 10000)\n",
            "(0.0, 0.0)\n",
            "\u001b[0;31mFile:\u001b[0m      ~/pilev2-venv/lib/python3.8/site-packages/scipy/integrate/_quadpack_py.py\n",
            "\u001b[0;31mType:\u001b[0m      function"
          ]
        }
      ],
      "source": [
        "integrate?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "def probability(b, x, r):\n",
        "    return (1 - \n",
        "        (1 - (x ** r))\n",
        "            ** b)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How to determine the B, R optimal params given a \n",
        "SIMILARITY threshold and a number of permutations\n",
        "\n",
        "This code defines a function false_positive_probability(threshold: float, b: int, r: int) that calculates the probability of a false positive in the context of Locality-Sensitive Hashing (LSH).\n",
        "\n",
        "This function takes in three arguments:\n",
        "\n",
        "- threshold is a float representing a similarity threshold\n",
        "- b is an integer representing the number of hash tables used\n",
        "- r is an integer representing the number of hash functions per table\n",
        "\n",
        "It uses an inner function proba(s) which calculates the probability that any two items that are similar to each other by at least s will be hashed to the same bucket. The inner function returns a probability value, and this probability is used in the outer function.\n",
        "\n",
        "The outer function then use integrate function which is not provided here and calculates the area under the curve of this probability function between 0.0 and the given threshold and returns the result as the probability of false positive.\n",
        "\n",
        "This code is based on datasketch library, The datasketch library provides a variety of algorithms for performing approximate nearest neighbor search in high-dimensional spaces, including LSH."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "r = 1\n",
        "def proba_original(s):\n",
        "    return 1 - (1 - s ** float(r)) ** float(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 0.7"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In Locality-Sensitive Hashing (LSH), the idea is to hash similar items to the same \"bucket\" with high probability.\n",
        "\n",
        "- To increase the chances of this happening, multiple hash tables are used. \n",
        "- Each table uses a different hash function, and when an item is hashed, it is hashed to each of the tables using the corresponding hash function.\n",
        "\n",
        "- The parameter b in the false_positive_probability function represents the number of hash tables used.\n",
        "\n",
        "- The larger the value of b, the more hash tables are used, and the higher the probability that similar items will be hashed to the same bucket in at least one of the tables. \n",
        "\n",
        "- This means that using a larger value of b will increase the chances of correctly identifying similar items, but it will also increase the number of hash tables needed to be searched, which can increase the running time.\n",
        "\n",
        "- It is worth noting that it is a trade-off between recall and precision when it comes to the number of hash tables. \n",
        "\n",
        "- In general, more hash tables would increase the recall but decrease the precision of the search and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "only size-1 arrays can be converted to Python scalars",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m integrate(proba_original, \u001b[39m0.0\u001b[39;49m, threshold)\n",
            "File \u001b[0;32m~/pilev2-venv/lib/python3.8/site-packages/scipy/integrate/_quadpack_py.py:463\u001b[0m, in \u001b[0;36mquad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst, complex_func)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m retval\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m     retval \u001b[39m=\u001b[39m _quad(func, a, b, args, full_output, epsabs, epsrel, limit,\n\u001b[1;32m    464\u001b[0m                    points)\n\u001b[1;32m    465\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[39mif\u001b[39;00m points \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/pilev2-venv/lib/python3.8/site-packages/scipy/integrate/_quadpack_py.py:575\u001b[0m, in \u001b[0;36m_quad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mif\u001b[39;00m points \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    574\u001b[0m     \u001b[39mif\u001b[39;00m infbounds \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 575\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39;49m_qagse(func,a,b,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    576\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    577\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39m_qagie(func,bound,infbounds,args,full_output,epsabs,epsrel,limit)\n",
            "Cell \u001b[0;32mIn[126], line 3\u001b[0m, in \u001b[0;36mproba_original\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mproba_original\u001b[39m(s):\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m s \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39mfloat\u001b[39m(r)) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39mfloat\u001b[39;49m(b)\n",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "integrate(proba_original, 0.0, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_error = float(\"inf\")\n",
        "opt = (0, 0)\n",
        "\n",
        "for hash_table in range(1, num_perm + 1):\n",
        "    max_r = int(num_perm / b)\n",
        "    for r in range(1, max_r + 1):\n",
        "        pass\n",
        "\n",
        "a, _ = integrate(probability, 0.0, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'scipy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[115], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Integrate func from a to b (possibly infinite interval) using a technique from the Fortran library QUADPACK.\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
          ]
        }
      ],
      "source": [
        "import scipy\n",
        "# Integrate func from a to b (possibly infinite interval) using a technique from the Fortran library QUADPACK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([896308, 690133,   6451], dtype=uint64)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hashvalues[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunks = NON_ALPHA.split(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def embed_func(\n",
        "    content: str,\n",
        "    idx: int,\n",
        "    *,\n",
        "    num_perm: int,\n",
        "    ngram_size: int,\n",
        "    hashranges: List[Tuple[int, int]],\n",
        "    permutations: np.ndarray,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Combined with some datasketch code to avoid dependency.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    content : str\n",
        "        The content to be embedded.\n",
        "    idx : int\n",
        "        The index of the content.\n",
        "    num_perm : int\n",
        "        The number of permutations.\n",
        "    ngram_size : int\n",
        "        The size of n-grams.\n",
        "    hashranges : List[Tuple[int, int]]\n",
        "        The ranges of hash values.\n",
        "    permutations : np.ndarray\n",
        "        The permutations for the minhash.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, Any]\n",
        "        The hash values in each range and the index.\n",
        "    \"\"\"\n",
        "    hashvalues = np.ones(num_perm, dtype=np.uint64) * MAX_HASH\n",
        "    # [MAX_HASH, MAX_HASH, .... , num_perm]\n",
        "    # 1. split the content with non alpha numeric char\n",
        "    # 2. create an ngram from the content_chunks to create a tokens SET\n",
        "    # 3. FOR EACH token in the SET create a hash (hv)\n",
        "    # 4.\n",
        "    chunks = NON_ALPHA.split(content)\n",
        "    content_as_ngram = {\" \".join(ngram) # TODO: are we losing data (punctuaction) here ??\n",
        "        for ngram in ngrams(chunks, ngram_size)}\n",
        "    hv = np.array([sha1_hash32(token.encode(\"utf-8\")) for token in content_as_ngram], dtype=np.uint64)  # noqa: E501\n",
        "    a, b = permutations\n",
        "    phv = np.bitwise_and(((hv * np.tile(a, (len(hv), 1)).T).T + b) % MERSENNE_PRIME, MAX_HASH)  # noqa: E501\n",
        "    hashvalues = np.vstack([phv, hashvalues]).min(axis=0)\n",
        "    Hs = [bytes(hashvalues[start:end].byteswap().data) for start, end in hashranges]\n",
        "    return {\"__signatures__\": Hs, \"__id__\": idx}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnionFind:\n",
        "    def __init__(self):\n",
        "        self.parent: Dict[int, int] = {}\n",
        "\n",
        "    def find(self, x):\n",
        "        if x not in self.parent:\n",
        "            self.parent[x] = x\n",
        "        if self.parent[x] != x:\n",
        "            self.parent[x] = self.find(self.parent[x])\n",
        "        return self.parent[x]\n",
        "\n",
        "    def union(self, x, y):\n",
        "        px = self.find(x)\n",
        "        py = self.find(y)\n",
        "        self.parent[px] = self.parent[py] = min(px, py)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A Union-find data structure is an algorithm that keeps track of a set of elements partitioned into a number of disjoint (non-overlapping) subsets. The Union-find algorithm is used to keep track of which elements are in the same subset and quickly perform union and find operations on these subsets.\n",
        "\n",
        "In the provided code, the UnionFind class is used to keep track of subsets of integers, which are represented by instances of the UnionFind class. The class has three methods:\n",
        "\n",
        "The __init__() method creates an empty dictionary named parent which is used to store the parent-child relationship of the elements in the subsets.\n",
        "\n",
        "The find(x) method takes an integer x as an input and returns the unique identifier of the subset which element x belongs to. This is done by following the chain of parent pointers up the tree until the parent pointer of x points to itself, which indicates that x is the root element of its subset.\n",
        "\n",
        "The union(x, y) method takes two integers x and y as input and unite two subsets which the element x and y respectively belong to. The method performs find on x and y to find the unique identifier of the subsets, and then set the root of the smaller set to point to the root of the larger set, effectively merging the two subsets into one.\n",
        "\n",
        "The parent dictionary is used to store the parent-child relationship of the elements in the subsets, and the find and union method use this dictionary to keep track of which elements are in the same subset and perform union and find operations on these subsets. The parent is an important part of Union-find data structure, it is used to maintain the disjoint sets of element in memory, to perform the union operation and find operation efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1 (main, Dec 23 2022, 09:40:27) [Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
